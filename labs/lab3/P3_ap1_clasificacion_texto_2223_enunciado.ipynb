{"cells":[{"cell_type":"markdown","metadata":{"id":"OUBRwgEu3yu1"},"source":["# Práctica 2: Procesamiento del Lenguaje Natural\n","\n","__Fecha de entrega: 8 de mayo de 2023__\n","\n","El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN. La práctica consta de 2 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n","\n","Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n","\n","Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"V3YxCTUW3yu9"},"outputs":[],"source":["RANDOM_STATE = 1234"]},{"cell_type":"markdown","metadata":{"id":"pn_YQLVL3yvA"},"source":["# Apartado 1: Análisis de sentimientos\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"de-i8w0s3yvC"},"source":["__Número de grupo: 20__\n","\n","__Nombres de los estudiantes: Alejandro Barrachina Argudo y Juan Pablo Corella Martín__"]},{"cell_type":"markdown","metadata":{"id":"yeVD_g2D3yvC"},"source":["## 1) Carga del conjunto de datos\n","\n","El fichero `IMBD_Dataset.csv` contiene opiniones de películas clasificadas en 2 categorías diferentes (positiva/negativa).\n","\n","Este set de datos se creó utilizando el \"IMDB Dataset of 50K Movie Reviews\", el cual contiene 50,000 reseñas de películas con un sentimiento positivo o negativo adjunto a ellas.\n","\n","Muestra un ejemplo de cada clase.\n","\n","Haz un estudio del conjunto de datos. ¿qué palabras aparecen más veces?, ¿tendría sentido normalizar de alguna manera el corpus?\n","\n","Crea una partición de los datos dejando el 80% para entrenamiento y el 20% restante para test usando la función `train_test_split` de sklearn. Comprueba que la distribución de los ejemplos en las clases es la misma en entrenamiento y test. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1487,"status":"ok","timestamp":1681627835928,"user":{"displayName":"ALBERTO DIAZ ESTEBAN","userId":"09370147929418307454"},"user_tz":-120},"id":"5YyPy4BDfzGQ","outputId":"d3637bed-fd90-4b68-9372-ed77292ae301"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# acceso a google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0csu2B8N3yvE"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":920,"status":"ok","timestamp":1681627836845,"user":{"displayName":"ALBERTO DIAZ ESTEBAN","userId":"09370147929418307454"},"user_tz":-120},"id":"kmcEfPgYf1Fk","outputId":"e7aed290-7b25-478a-8bed-3872fd756c12"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-ddc33f3a-9697-4f31-aaf1-94353c5e4277\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddc33f3a-9697-4f31-aaf1-94353c5e4277')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ddc33f3a-9697-4f31-aaf1-94353c5e4277 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ddc33f3a-9697-4f31-aaf1-94353c5e4277');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["imbd_file = '/content/drive/MyDrive/IA2/p3/IMDB_Dataset.csv'\n","\n","df=pd.read_csv(imbd_file)\n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["imbd_file = './IMDB_Dataset.csv'\n","\n","df = pd.read_csv(imbd_file)\n","df.head()\n"]},{"cell_type":"markdown","metadata":{"id":"r4rXv3xX3yvG"},"source":["## 2) Estudio del efecto de distintas representaciones y distintos algoritmos para resolver la tarea\n","\n","Construye distintas representaciones vectoriales basadas en lo contado en las clases de teoría (bolsas de palabras con 2 configuraciones distintas significativas) y utilízalas con 2 de los algoritmos estudiados (árboles de decisión y naive bayes)\n","\n","Para una única configuración, muestra algún mensaje tanto en su formato de texto original como en la versión vectorizada. ¿Qué palabras se han eliminado y por qué?\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/_alk/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["wpt = nltk.WordPunctTokenizer()\n","nltk.download('stopwords')\n","stop_words = nltk.corpus.stopwords.words('english')\n","\n","\n","def normalize_document(doc):\n","    # lower case and remove special characters\\whitespaces\n","    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I | re.A)\n","    doc = doc.lower()\n","    doc = doc.strip()\n","    # tokenize document\n","    tokens = wpt.tokenize(doc)\n","    # filter stopwords out of document\n","    filtered_tokens = [token for token in tokens if token not in stop_words]\n","    # re-create document from filtered tokens\n","    doc = ' '.join(filtered_tokens)\n","    return doc\n","\n","\n","normalize_corpus = np.vectorize(normalize_document)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imdb_norm \u001b[39m=\u001b[39m normalize_corpus(df)\n","File \u001b[0;32m/usr/lib/python3.10/site-packages/numpy/lib/function_base.py:2329\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2326\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[1;32m   2327\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[0;32m-> 2329\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n","File \u001b[0;32m/usr/lib/python3.10/site-packages/numpy/lib/function_base.py:2412\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2409\u001b[0m \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[1;32m   2410\u001b[0m inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n\u001b[0;32m-> 2412\u001b[0m outputs \u001b[39m=\u001b[39m ufunc(\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   2414\u001b[0m \u001b[39mif\u001b[39;00m ufunc\u001b[39m.\u001b[39mnout \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   2415\u001b[0m     res \u001b[39m=\u001b[39m asanyarray(outputs, dtype\u001b[39m=\u001b[39motypes[\u001b[39m0\u001b[39m])\n","Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mnormalize_document\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     12\u001b[0m tokens \u001b[39m=\u001b[39m wpt\u001b[39m.\u001b[39mtokenize(doc)\n\u001b[1;32m     13\u001b[0m \u001b[39m# filter stopwords out of document\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m filtered_tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words]\n\u001b[1;32m     15\u001b[0m \u001b[39m# re-create document from filtered tokens\u001b[39;00m\n\u001b[1;32m     16\u001b[0m doc \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_tokens)\n","Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m tokens \u001b[39m=\u001b[39m wpt\u001b[39m.\u001b[39mtokenize(doc)\n\u001b[1;32m     13\u001b[0m \u001b[39m# filter stopwords out of document\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m filtered_tokens \u001b[39m=\u001b[39m [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokens \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words]\n\u001b[1;32m     15\u001b[0m \u001b[39m# re-create document from filtered tokens\u001b[39;00m\n\u001b[1;32m     16\u001b[0m doc \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(filtered_tokens)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["imdb_norm = normalize_corpus(df)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"6WLFEg9B6Uu9"},"outputs":[{"data":{"text/plain":["array([[1, 0],\n","       [0, 1]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","cv = CountVectorizer()\n","cv_matrix = cv.fit_transform(df)\n","cv_matrix = cv_matrix.toarray()\n","cv_matrix\n"]},{"cell_type":"markdown","metadata":{"id":"XmM1ftJe3yvK"},"source":["## 3) Análisis comparativo final\n","\n","Se han entrenado varios clasificadores usando vectorizaciones diferentes de los datos. Compara las diferencias entre representaciones para un mismo algoritmo y entre algoritmos. Explica a qué crees que se deben las diferencias.\n","\n","Analiza con detalle el mejor clasificador de cada tipo. Indica las palabras más relevantes. Busca un ejemplo mal clasificado de cada clase, justifica el error ¿se te ocurre alguna forma de solucionarlo?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qU0UFbSm9NQm"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
