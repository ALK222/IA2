{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpd0gkGnpzXT"
   },
   "source": [
    "# Práctica 2: Procesamiento del Lenguaje Natural\n",
    "\n",
    "__Fecha de entrega: 17 de abril de 2022__\n",
    "\n",
    "El objetivo de esta práctica es aplicar los conceptos teóricos vistos en clase en el módulo de PLN. La práctica consta de 2 notebooks que se entregarán simultáneamente en la tarea de entrega habilitada en el Campus  Virtual.\n",
    "\n",
    "Lo más importante en esta práctica no es el código Python, sino el análisis de los datos y modelos que construyas y las explicaciones razonadas de cada una de las decisiones que tomes. __No se valorarán trozos de código o gráficas sin ningún tipo de contexto o explicación__.\n",
    "\n",
    "Finalmente, recuerda establecer el parámetro `random_state` en todas las funciones que tomen decisiones aleatorias para que los resultados sean reproducibles (los resultados no varíen entre ejecuciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IBx1oG6bpzXY"
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 133"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkJPtLPRpzXa"
   },
   "source": [
    "# Apartado 2: Recuperación de información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWQ9sB-ApzXc"
   },
   "source": [
    "__Número de grupo: XX__\n",
    "\n",
    "__Nombres de los estudiantes: XXX y XXX__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1iFIS_EpzXc"
   },
   "source": [
    "## 1) Carga del conjunto de datos\n",
    "\n",
    "El fichero `BBC News.csv` contiene noticias clasificadas en 5 categorías diferentes. \n",
    "\n",
    "Carga los datos en un dataframe teniendo en cuenta que la columna `ArticleId` es un identificador de la noticia y por lo tanto no lo vamos a usar. \n",
    "\n",
    "Estudia el tamaño del conjunto de datos y la proporción de noticias que pertenecen a cada una de las categorías.\n",
    "\n",
    "Crea una partición estratificada de los datos dejando el 80% para entrenamiento y el 20% restante para test usando la función `train_test_split` de sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ufbBvGcnpzXe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = 'BBC News.csv'\n",
    "csv = pd.read_csv(file, sep=',')\n",
    "df = pd.DataFrame(csv, columns = ['Text','Category']) #importar csv sin ArticleId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            346\n",
       "business         336\n",
       "politics         274\n",
       "entertainment    273\n",
       "tech             261\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudia el tamaño del conjunto de datos y la proporción de noticias que pertenecen a cada una de las categorías.\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "df['Category'].value_counts() #contar veces que aparece cada valor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  Category\n",
      "0     warning over us pensions deficit taxpayers may...  business\n",
      "1     collins calls for chambers return world 100m c...     sport\n",
      "2     safety alert as gm recalls cars the world s bi...  business\n",
      "3     jp morgan admits us slavery links thousands of...  business\n",
      "4     clarke to press on with id cards new home secr...  politics\n",
      "...                                                 ...       ...\n",
      "1187  us in eu tariff chaos trade row the us has ask...  business\n",
      "1188  benitez  to launch morientes bid  liverpool ma...     sport\n",
      "1189  progress on new internet domains by early 2005...      tech\n",
      "1190  mauresmo opens with victory in la amelie maure...     sport\n",
      "1191  henman decides to quit davis cup tim henman ha...     sport\n",
      "\n",
      "[1192 rows x 2 columns]\n",
      "                                                  Text       Category\n",
      "0    boris opposes mayor apology ken livingstone sh...       politics\n",
      "1    wenger signs new deal arsenal manager arsene w...          sport\n",
      "2    telewest to challenge sky plus cable firm tele...           tech\n",
      "3    concern over rfid tags consumers are very conc...           tech\n",
      "4    mobiles  not media players yet  mobiles are no...           tech\n",
      "..                                                 ...            ...\n",
      "293  nintendo adds media playing to ds nintendo is ...           tech\n",
      "294  will tory tax cuts lift spirits  michael howar...       politics\n",
      "295  yachvili savours france comeback france scrum-...          sport\n",
      "296  police praise  courageous  ozzy rock star ozzy...  entertainment\n",
      "297  iran budget seeks state sell-offs iran s presi...       business\n",
      "\n",
      "[298 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crea una partición estratificada de los datos dejando el 80% para entrenamiento y el 20% restante para test\n",
    "# usando la función `train_test_split` de sklearn. \n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2,random_state=RANDOM_STATE) #mezclo y cojo el 20% para prueba\n",
    "\n",
    "#Como los indices no se corresponden a la posicion de la lista y sufrimos el riesgo de acceder\n",
    "#a una posicion vacía, los reajustamos con un dataframe nuevo\n",
    "\n",
    "aux = {'Text': train_data.Text.tolist(), \n",
    "        'Category': train_data.Category.tolist()}\n",
    "train_data = pd.DataFrame(aux, columns=['Text', 'Category'])\n",
    "\n",
    "aux = {'Text': test_data.Text.tolist(),\n",
    "        'Category': test_data.Category.tolist()}\n",
    "test_data = pd.DataFrame(aux, columns=['Text', 'Category'])\n",
    "\n",
    "print(train_data) #entrenamiento\n",
    "print(test_data) #prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fx5hJC7pzXf"
   },
   "source": [
    "## 2) Representación basada en bolsa de palabras y tf-idf\n",
    "\n",
    "La primera vectorización que vamos a usar representará los mensajes usando el modelo de bolsa de palabras, monogramas y el valor tf-idf de cada palabra. Usa como _stop words_ las que vienen configuradas por defecto para el inglés.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test. Muestra algún mensaje tanto en su formato de texto original como en la versión vectorizada. ¿Qué palabras se han eliminado y por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wKdL2-VSpzXg"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "   \n",
    "vectorizer = CountVectorizer(stop_words='english', binary=False, ngram_range=(1,1), token_pattern=r'(?u)\\b[A-Za-z]+\\b') \n",
    "\n",
    "# Tomamos los textos del conjunto de entrenamiento y los transformamos en \n",
    "# una matriz de datos (palabras) según el diccionario estándar\n",
    "train_vector_data=vectorizer.fit_transform(train_data.Text)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "test_vector_data=vectorizer.transform(test_data.Text)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "\n",
    "tfidftrans = TfidfTransformer()\n",
    "\n",
    "train_preprocessed = tfidftrans.fit_transform(train_vector_data)\n",
    "test_preprocessed = tfidftrans.transform(test_vector_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "def write_terms (feature_names, data, vector_data, index):\n",
    "    '''\n",
    "    Escribe los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - data: lista de mensajes original (si data==None no se muestra el mensaje original)\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    # máscara para seleccionar sólo el mensaje en posición index\n",
    "    mask=vector_data[index,:]>0\n",
    "    \n",
    "    # términos que aparecen en ese mensaje vectorizado\n",
    "    terminos = ma.array(feature_names, mask = ~(mask[0].toarray()))\n",
    "    \n",
    "    # mostrar mensaje original\n",
    "    if data is not None:\n",
    "        print('Mensaje', index, ':', data[index])\n",
    "    \n",
    "    # mostrar términos que aparecen en el mensaje vectorizado\n",
    "    print('Mensaje', index, 'vectorizado:', terminos.compressed(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje 0 : warning over us pensions deficit taxpayers may have to bail out the us agency that protects workers  pension funds  leading economists have warned.  with the pension benefit guaranty corporation (pbgc) some £23bn (£12m) in deficit  the financial economists roundtable (fer) wants congress to act. instead of taxpayers having to pick up the bill  the fer wants congressmen to change the pbgc s funding rules. the fer says firms should not have been allowed to reduce the insurance premiums they pay into the pbgc fund. the fer blames this on a 2004 law  in a statement signed by several members  who include nobel economics laureate william sharpe. it said it was  dismayed  at the situation and wants congress to overturn the legislation.  cash-strapped us companies  including those in the airline  car-making and steel industries  had argued in favour of the 2004 rule change  claiming that funding the insurance premiums adequately would force them to have to cut jobs.  with a little firmer hand on the pensions issues in the us  i think that congress could avoid having to turn to the taxpayer and instead turn the obligations back onto the companies that deserve to pay them   said professor dennis logue  dean of price college of business at the university of oklahoma. the pbgc was founded in 1974 to protect workers  retirement rights. its most recent action came last week when it took control of the pilots  pension scheme at united airlines. with united battling bankruptcy  the carrier had wanted to use the money set aside for pensions to finance running costs. the company has an estimated $2.9bn hole in its pilots  pension scheme  which the pbgc will now guarantee.\n",
      "Mensaje 0 vectorizado: ['act' 'action' 'adequately' 'agency' 'airline' 'airlines' 'allowed'\n",
      " 'argued' 'aside' 'avoid' 'bail' 'bankruptcy' 'battling' 'benefit'\n",
      " 'blames' 'business' 'came' 'car' 'carrier' 'cash' 'change' 'claiming'\n",
      " 'college' 'companies' 'company' 'congress' 'congressmen' 'control'\n",
      " 'corporation' 'costs' 'cut' 'dean' 'deficit' 'dennis' 'deserve'\n",
      " 'dismayed' 'economics' 'economists' 'estimated' 'favour' 'fer' 'finance'\n",
      " 'financial' 'firmer' 'firms' 'force' 'founded' 'fund' 'funding' 'funds'\n",
      " 'guarantee' 'guaranty' 'hand' 'having' 'hole' 'include' 'including'\n",
      " 'industries' 'instead' 'insurance' 'issues' 'jobs' 'laureate' 'law'\n",
      " 'leading' 'legislation' 'little' 'logue' 'making' 'members' 'money'\n",
      " 'nobel' 'obligations' 'oklahoma' 'overturn' 'pay' 'pbgc' 'pension'\n",
      " 'pensions' 'pick' 'pilots' 'premiums' 'price' 'professor' 'protect'\n",
      " 'protects' 'recent' 'reduce' 'retirement' 'rights' 'roundtable' 'rule'\n",
      " 'rules' 'running' 's' 'said' 'says' 'scheme' 'set' 'sharpe' 'signed'\n",
      " 'situation' 'statement' 'steel' 'strapped' 'taxpayer' 'taxpayers' 'think'\n",
      " 'took' 'turn' 'united' 'university' 'use' 'wanted' 'wants' 'warned'\n",
      " 'warning' 'week' 'william' 'workers'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Muestra algún mensaje tanto en su formato de texto original como en la versión vectorizada. ¿Qué palabras se han eliminado y por qué?\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "write_terms(feature_names, train_data['Text'], train_preprocessed, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno.\n",
    "# Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def knn(query, X_train, k):\n",
    "    '''Devuelve los índices de los k documentos de entrenamiento más similares a la consulta usando \n",
    "    la similitud del coseno.\n",
    "    \n",
    "    Parámetros:\n",
    "    - query: documento consulta vectorizado\n",
    "    - X_train: documentos de entrenamiento vectorizados\n",
    "    - k: número de documentos a recuperar\n",
    "    \n",
    "    Devuelve:\n",
    "    - índices de los k documentos más similares a la consulta.\n",
    "    '''\n",
    "    \n",
    "    # Necesitamos un vector de dimensión (1, X). Si se pasa un vector de dimensión X, transformarlo\n",
    "    if len(query.shape) == 1:\n",
    "        query = query.reshape(1, -1)\n",
    "\n",
    "    simil = cosine_similarity(query, X_train)\n",
    "    simil_idx = np.argsort(simil.flatten())\n",
    "    simil_idx = simil_idx[::-1]\n",
    "    return simil_idx[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(y_selected, y_real, k):\n",
    "    '''Devuelve la precisión @k de los documentos seleccionados.\n",
    "    \n",
    "    Parametros:\n",
    "    - y_selected: etiquetas de los documentos seleccionados (se usan los k primeros)\n",
    "    - y_real: etiqueta de la categoría correcta\n",
    "    - k: número de documentos que se tienen en cuenta\n",
    "    \n",
    "    Devuelve:\n",
    "    - Precisión@k\n",
    "    '''\n",
    "    \n",
    "    return np.sum(y_selected[:k] == y_real) / k * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_precisions_per_class(X_train, y_train, X_test, y_test, k):\n",
    "    '''Devuelve las precision@k media para cada una de las classes.\n",
    "    \n",
    "    Parámetros:\n",
    "    - X_train: documentos de entrenamiento vectorizados.\n",
    "    - y_train: etiquetas de los documentos de entrenamiento.\n",
    "    - X_test: documentos vectorizados que se usan como consultas\n",
    "    - y_test: etiquetas de los documentos que se usan como consultas\n",
    "    - k: número de documentos considerados a recuperar por la consulta\n",
    "    \n",
    "    Devuelve:\n",
    "    - Diccionario clase -> precisión en tanto por ciento.\n",
    "    '''\n",
    "    \n",
    "    # diccionario categoría -> lista de precisiones\n",
    "    y_precisions = {y: [] for y in np.unique(y_test)}\n",
    "    \n",
    "    # Calcular precision@k para cada consulta\n",
    "    for x_query, y_query in zip(X_test, y_test):\n",
    "        idx = knn(x_query, X_train, k)\n",
    "        y_selected = np.take(y_train, idx)\n",
    "        precision = precision_at_k(y_selected, y_query, k)\n",
    "        y_precisions[y_query].append(precision)\n",
    "        \n",
    "    # Calcular medias\n",
    "    for y in y_precisions:\n",
    "        y_precisions[y] = np.mean(y_precisions[y])\n",
    "    \n",
    "    return y_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 83.88888888888889,\n",
       " 'entertainment': 78.33333333333333,\n",
       " 'politics': 87.9245283018868,\n",
       " 'sport': 97.74193548387096,\n",
       " 'tech': 87.84313725490196}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5 = mean_precisions_per_class(train_preprocessed, train_data['Category'], test_preprocessed, test_data['Category'], 5)\n",
    "    \n",
    "p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dibuja los resultados en un diagrama de barras y comenta las clases en las que se comporta mejor y peor.\n",
    "# ¿Crees que los resultados son buenos?\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_p5 = pd.DataFrame.from_dict(p5, orient='index', columns=['precision@5'])\n",
    "\n",
    "df_p5[\"target\"] = ['business', 'entertainment', 'politics','sport', 'tech']\n",
    "\n",
    "d = df_p5.set_index(\"target\")\n",
    "\n",
    "d.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLICAR MOVIDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH7sldldpzXi"
   },
   "source": [
    "## 3) Representación basada en word-embeddings y tf-idf\n",
    "\n",
    "La segunda vectorización que vamos a usar representará los mensajes usando usando word-embeddings usando como los pesos tf-idf de cada palabra. Al igual que en el apartado anterior, usaremos monogramas y las _stop words_ que vienen configuradas por defecto para el inglés. Recuerda usar como vocabulario para vectorizar el vocabulario del fichero con las word-embeddings.\n",
    "\n",
    "Aplica la vectorización a los conjuntos de mensajes de entrenamiento y test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Traducimos el fichero glove a un fichero con formato word2vec\n",
    "glove_file = 'words.txt'\n",
    "\n",
    "# Gensim 4 puede transformar de glove a word2vec directamente\n",
    "we_model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# En Gensim 4 se pueden obtener de la siguiente manera\n",
    "# we_vocabulary = sorted(model.key_to_index.keys(), key=lambda word: model.get_vecattr(word, \"count\"), reverse=True)\n",
    "we_vocabulary = list(we_model.key_to_index.keys())\n",
    "\n",
    "we_vectorizer = CountVectorizer(vocabulary = we_vocabulary, stop_words='english', binary=False,ngram_range=(1,1), token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
    "\n",
    "we_train_vector_data = we_vectorizer.fit_transform(train_data.Text)\n",
    "\n",
    "# Tomamos los textos del conjunto de test y los transformamos en una matriz\n",
    "# de palabras. Al usar \"transform\" toma como referencia únicamente las palabras\n",
    "# encontradas en el conjunto de entrenamiento\n",
    "we_test_vector_data=we_vectorizer.transform(test_data.Text)\n",
    "\n",
    "we_feature_names = we_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_tfidftrans = TfidfTransformer()\n",
    "\n",
    "we_train_preprocessed = we_tfidftrans.fit_transform(we_train_vector_data)\n",
    "we_test_preprocessed = we_tfidftrans.transform(we_test_vector_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula la precisión@5 de cada una de las clases usando como consultas los documentos de la partición de test y la similitud del coseno. Vamos a considerar que un documento recuperado es relevante cuando pertenezca a la misma clase que la consulta.\n",
    "\n",
    "Dibuja los resultados en un diagrama de barras y compara los resultados con los del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': 87.77777777777777,\n",
       " 'entertainment': 81.66666666666667,\n",
       " 'politics': 85.66037735849056,\n",
       " 'sport': 96.7741935483871,\n",
       " 'tech': 84.70588235294117}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p5 = mean_precisions_per_class(we_train_preprocessed, train_data['Category'], we_test_preprocessed, test_data['Category'], 5)\n",
    "    \n",
    "p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_p5 = pd.DataFrame.from_dict(p5, orient='index', columns=['precision@5'])\n",
    "\n",
    "df_p5[\"target\"] = ['business', 'entertainment', 'politics','sport', 'tech']\n",
    "\n",
    "d = df_p5.set_index(\"target\")\n",
    "\n",
    "d.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-J6GYut4DGu"
   },
   "source": [
    "## 4) Análisis de errores\n",
    "\n",
    "Vamos a investigar los resultados para entender mejor dónde están fallando los procesos de recuperación. Sigue los siguientes pasos.\n",
    "\n",
    "\n",
    "1. Identifica la categoría de noticias donde la precisión media haya mejorado más al incorporar word-embeddings\n",
    "2. Para dicha categoría, identifica la consulta donde la precisión haya mejorado más al usar word-embeddings\n",
    "3. Muestra el texto original de la consulta y los términos que aparecen en las dos vectorizaciones tf-idf que usamos (recuerda que usamos diccionarios distintos para las vectorizaciones bolsa de palabras y word-embeddings).\n",
    "4. Identifica las noticias recuperadas para dicha consulta para las dos aproximaciones y sus categorías (TF-IDF puro y con word-embeddings)\n",
    "5. Muestra la intersección de términos entre la consulta y la primera noticia mal recuperada usando TF-IDF puro.\n",
    "6. Muestra la intersección de términos entre la consulta y la última noticia bien recuperada usando word-embeddings.\n",
    "7. A la luz de todo lo anterior, razona sobre por qué crees que el TF-IDF no fue capaz de clasificar bien la noticia y el word-embedding sí.\n",
    "\n",
    "\n",
    "Puedes usar el código que calcula la intersección de términos que ponemos a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisions_per_class(X_train, y_train, X_test, y_test, k):\n",
    "    '''Devuelve las precision@k para cada una de las classes.\n",
    "    \n",
    "    Parámetros:\n",
    "    - X_train: documentos de entrenamiento vectorizados.\n",
    "    - y_train: etiquetas de los documentos de entrenamiento.\n",
    "    - X_test: documentos vectorizados que se usan como consultas\n",
    "    - y_test: etiquetas de los documentos que se usan como consultas\n",
    "    - k: número de documentos considerados a recuperar por la consulta\n",
    "    \n",
    "    Devuelve:\n",
    "    - Diccionario clase -> [[indice noticia,precision]].\n",
    "    '''\n",
    "    \n",
    "    # diccionario categoría -> lista de precisiones\n",
    "    y_precisions = {y: [] for y in np.unique(y_test)}\n",
    "    \n",
    "    index = 0 #contamos las noticias para obtener los indices\n",
    "    \n",
    "    # Calcular precision@k para cada consulta\n",
    "    for x_query, y_query in zip(X_test, y_test):\n",
    "        idx = knn(x_query, X_train, k)\n",
    "        y_selected = np.take(y_train, idx)\n",
    "        precision = [index,precision_at_k(y_selected, y_query, k)] \n",
    "        y_precisions[y_query].append(precision)\n",
    "        index+=1\n",
    "    \n",
    "    return y_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 : 0.0 60.0\n",
      "50 : 60.0 100.0\n",
      "58 : 80.0 100.0\n",
      "65 : 80.0 100.0\n",
      "80 : 80.0 100.0\n",
      "100 : 60.0 100.0\n",
      "113 : 60.0 100.0\n",
      "123 : 80.0 100.0\n",
      "151 : 80.0 100.0\n",
      "172 : 80.0 100.0\n",
      "192 : 80.0 100.0\n",
      "262 : 40.0 60.0\n",
      "269 : 0.0 20.0\n",
      "281 : 40.0 100.0\n",
      "285 : 40.0 60.0\n",
      "297 : 60.0 100.0\n"
     ]
    }
   ],
   "source": [
    "pre = precisions_per_class(train_preprocessed, train_data['Category'], test_preprocessed, test_data['Category'], 5)\n",
    "we_pre = precisions_per_class(we_train_preprocessed, train_data['Category'], we_test_preprocessed, test_data['Category'], 5)\n",
    "\n",
    "for i in range(0, len(pre['business'])):\n",
    "    if (pre['business'][i][1] < we_pre['business'][i][1]): #el segundo elemento es la precision\n",
    "        print(pre['business'][i][0], ':',pre['business'][i][1],we_pre['business'][i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Hay varias consultas con un incremento del 60% en la precisión, por lo que tomaremos la primera encontrada al pasar de no tener ninguna similitud a una del 60% (i = 35)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "RUat8DCRLYs1"
   },
   "outputs": [],
   "source": [
    "#3. Muestra el texto original de la consulta y los términos que aparecen en las dos vectorizaciones tf-idf que usamos\n",
    "#(recuerda que usamos diccionarios distintos para las vectorizaciones bolsa de palabras y word-embeddings).\n",
    "\n",
    "def terms_in_message(feature_names,vector_data,index):\n",
    "    '''\n",
    "    Devuelve un conjunto los términos presentes en un mensaje representado como bolsa de palabras.\n",
    "    \n",
    "    - feature_names: terminos usados para vectorizar\n",
    "    - vector_data: matriz (dispersa) de mensaje vectorizados\n",
    "    - index: posición del mensaje a mostrar\n",
    "    '''\n",
    "    mensaje=vector_data[index,:]>0\n",
    "    terminos_presentes = ma.array(feature_names, mask = ~(mensaje[0].toarray()))\n",
    "\n",
    "    return set(terminos_presentes.compressed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mensaje:\n",
      " mcdonald s boss bell dies aged 44 charlie bell  the straight-talking former head of fast-food giant mcdonald s  has died of cancer aged 44.  mr bell was diagnosed with colorectal cancer in may last year  a month after taking over the top job. he resigned in november to fight the illness. joining the company as a 15-year-old part-time worker  mr bell quickly moved through its ranks  becoming australia s youngest store manager at 19. a popular go-getter  he is credited with helping revive mcdonald s sales. mr bell leaves a wife and daughter.  as we mourn his passing  i ask you to keep charlie s family in your hearts and prayers   chief executive james skinner said in a statement.  and remember that in his abbreviated time on this earth  charlie lived life to the fullest.   no matter what cards life dealt  charlie stayed centred on his love for his family and for mcdonald s.   after running the company s australian business in the 1990s  mr bell moved to the us in 1999 to run operations in asia  africa and the middle east. in 2001  he took over the reins in europe  mcdonald s second most important market. he became chief operating officer and president in 2002. mr bell took over as chief executive after his predecessor as ceo  jim cantalupo  died suddenly of a heart attack in april. having worked closely with mr cantalupo  who came out of retirement to turn mcdonald s around  mr bell focused on boosting demand at existing restaurants rather than follow a policy of rapid expansion. he had promised not to let the company get  fat  dumb and happy   and  according to reuters  once told analysts that he would shove a fire hose down the throat of competitors if he saw them drowning. mr bell oversaw mcdonald s  i m lovin  it  advertising campaign and introduced successes such as mccafe  now the biggest coffee shop brand in australia and new zealand. colleagues said that mr bell was proud of his humble beginnings  helping out behind cash tills and clearing tables when visiting restaurants.\n",
      "\n",
      "Bolsa de palabras: ['according', 'advertising', 'africa', 'aged', 'analysts', 'april', 'asia', 'ask', 'attack', 'australia', 'australian', 'beginnings', 'bell', 'biggest', 'boosting', 'boss', 'brand', 'business', 'came', 'campaign', 'cancer', 'cards', 'cash', 'centred', 'ceo', 'charlie', 'chief', 'clearing', 'closely', 'coffee', 'colleagues', 'company', 'competitors', 'credited', 'daughter', 'dealt', 'demand', 'diagnosed', 'died', 'dies', 'drowning', 'dumb', 'earth', 'east', 'europe', 'executive', 'existing', 'expansion', 'family', 'fast', 'fat', 'fight', 'focused', 'follow', 'food', 'fullest', 'giant', 'happy', 'having', 'head', 'heart', 'hearts', 'helping', 'humble', 'illness', 'important', 'introduced', 'james', 'jim', 'job', 'joining', 'leaves', 'let', 'life', 'lived', 'love', 'm', 'manager', 'market', 'matter', 'mcdonald', 'middle', 'month', 'moved', 'mr', 'new', 'november', 'officer', 'old', 'operating', 'operations', 'oversaw', 'passing', 'policy', 'popular', 'predecessor', 'president', 'promised', 'proud', 'quickly', 'ranks', 'rapid', 'remember', 'resigned', 'restaurants', 'retirement', 'reuters', 'revive', 'run', 'running', 's', 'said', 'sales', 'saw', 'second', 'shop', 'shove', 'skinner', 'statement', 'stayed', 'store', 'straight', 'successes', 'suddenly', 'taking', 'talking', 'throat', 'tills', 'time', 'told', 'took', 'turn', 'visiting', 'wife', 'worked', 'worker', 'year', 'youngest', 'zealand']\n",
      "\n",
      "Word-embeddings: ['abbreviated', 'according', 'advertising', 'aged', 'analysts', 'attack', 'beginnings', 'biggest', 'boosting', 'business', 'campaign', 'cards', 'centred', 'chief', 'clearing', 'closely', 'colleagues', 'company', 'competitors', 'credited', 'daughter', 'dealt', 'demand', 'diagnosed', 'died', 'drowning', 'dumb', 'executive', 'existing', 'expansion', 'fight', 'focused', 'follow', 'food', 'fullest', 'giant', 'having', 'head', 'heart', 'hearts', 'helping', 'illness', 'important', 'introduced', 'joining', 'leaves', 'let', 'lived', 'm', 'manager', 'matter', 'month', 'mourn', 'moved', 'officer', 'operating', 'operations', 'oversaw', 'passing', 'policy', 'popular', 'prayers', 'predecessor', 'president', 'promised', 'quickly', 'ranks', 'rapid', 'reins', 'remember', 'resigned', 'restaurants', 'retirement', 'revive', 'run', 'running', 's', 'said', 'sales', 'second', 'shop', 'shove', 'statement', 'stayed', 'store', 'straight', 'successes', 'suddenly', 'tables', 'taking', 'talking', 'throat', 'tills', 'told', 'took', 'turn', 'visiting', 'wife', 'worked', 'worker', 'year', 'youngest']\n"
     ]
    }
   ],
   "source": [
    "print('Mensaje:\\n',test_data.Text.tolist()[35])\n",
    "\n",
    "print('\\nBolsa de palabras:', sorted(terms_in_message(feature_names,test_preprocessed,35)))\n",
    "print('\\nWord-embeddings:',sorted(terms_in_message(we_feature_names,we_test_preprocessed,35)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF puro:\n",
      "890 politics\n",
      "432 entertainment\n",
      "425 sport\n",
      "92 politics\n",
      "1159 politics\n",
      "\n",
      "TF-IDF con Word-embeddings:\n",
      "492 business\n",
      "1068 entertainment\n",
      "652 entertainment\n",
      "219 business\n",
      "230 business\n"
     ]
    }
   ],
   "source": [
    "#4. Identifica las noticias recuperadas para dicha consulta para las dos aproximaciones y sus categorías (TF-IDF puro y con word-embeddings)\n",
    "tf_noti = knn(test_preprocessed[35], train_preprocessed, 5)\n",
    "we_noti = knn(we_test_preprocessed[35], we_train_preprocessed, 5)\n",
    "\n",
    "print('TF-IDF puro:')\n",
    "for elem in tf_noti:\n",
    "    print(elem, train_data.Category.tolist()[elem])\n",
    "    \n",
    "\n",
    "print('\\nTF-IDF con Word-embeddings:')\n",
    "for elem in we_noti:\n",
    "    print(elem, train_data.Category.tolist()[elem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bell', 'chief', 'mr', 's', 'said']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Muestra la intersección de términos entre la consulta y la primera noticia mal recuperada usando TF-IDF puro.\n",
    "test_terms = sorted(terms_in_message(feature_names,test_preprocessed,35))\n",
    "train_terms = sorted(terms_in_message(feature_names,train_preprocessed,890))\n",
    "\n",
    "inter = []\n",
    "for elem in train_terms:\n",
    "    if elem in test_terms:\n",
    "        inter.append(elem)\n",
    "\n",
    "inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biggest',\n",
       " 'boosting',\n",
       " 'business',\n",
       " 'demand',\n",
       " 'giant',\n",
       " 'popular',\n",
       " 's',\n",
       " 'said',\n",
       " 'sales',\n",
       " 'year']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Muestra la intersección de términos entre la consulta y la última noticia bien recuperada usando word-embeddings.\n",
    "\n",
    "we_test_terms = sorted(terms_in_message(we_feature_names,we_test_preprocessed,35))\n",
    "we_train_terms = sorted(terms_in_message(we_feature_names,we_train_preprocessed,230))\n",
    "\n",
    "we_inter = []\n",
    "for elem in we_train_terms:\n",
    "    if elem in we_test_terms:\n",
    "        we_inter.append(elem)\n",
    "\n",
    "we_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. A la luz de todo lo anterior, razona sobre por qué crees que el TF-IDF no fue capaz de clasificar bien la noticia y el word-embedding sí."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "P2_recuperacion_informacion_2122_enunciado.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
